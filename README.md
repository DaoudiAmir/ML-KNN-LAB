# ğŸ¯ K-Nearest Neighbors (KNN) Analysis Lab

## ğŸ“š Overview
This repository contains a comprehensive analysis of the K-Nearest Neighbors (KNN) algorithm, focusing on:
- Impact of k parameter selection
- Training data size effects
- Test data size influence
- Decision boundary analysis

## ğŸ“ Repository Structure
- `knn_analysis.md`: Detailed analysis of decision boundaries based on k parameter
- `knn_precision_analysis.md`: Analysis of k's impact on model precision
- `test_size_analysis.md`: Study of test data size effects
- `training_size_analysis.md`: Analysis of training data size impact
- `training_size_protocol.md`: Experimental protocol for training size analysis

## ğŸ” Key Findings
1. **Optimal k Value**: k=8 provides the best balance between bias and variance
2. **Training Size**: Performance stabilizes at ~70% of training data
3. **Test Size**: ~30% of data provides reliable evaluation metrics

## ğŸ› ï¸ Implementation Details
- Algorithm: K-Nearest Neighbors (KNN)
- Language: Python
- Key Libraries: scikit-learn, numpy, matplotlib

## ğŸ“Š Results
- Detailed analysis of model behavior with varying parameters
- Comprehensive evaluation of model performance
- Practical recommendations for parameter selection

## ğŸ“ Educational Purpose
This lab is part of the Machine Learning course at ESIEA, designed to provide hands-on experience with KNN algorithm implementation and analysis.
